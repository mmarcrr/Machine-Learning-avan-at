{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S12 T01: Pipelines, grid search i text mining\n",
    "\n",
    "## Descripció\n",
    "Comencem a familiaritzar-nos amb Pipelines, grid search i text mining !!! Comencem amb uns quants exercicis bàsics\n",
    "\n",
    "## Nivell 1\n",
    "### - Exercici 1\n",
    "Agafa el conjunt de dades que vulguis i realitza un pipeline i un gridsearch aplicant l'algorisme de Random Forest.\n",
    "\n",
    "### - Exercici 2\n",
    "Agafa un text en anglès que vulguis, i calcula'n la freqüència de les paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>74.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347060</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kraeff, Mr. Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349253</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hosono, Mr. Masabumi</td>\n",
       "      <td>male</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>237798</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>474</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jerwan, Mrs. Amin S (Marie Marthe Thuillard)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/AH Basle 541</td>\n",
       "      <td>13.7917</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brewe, Dr. Arthur Jackson</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112379</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Salonen, Mr. Johan Werner</td>\n",
       "      <td>male</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3101296</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Master. Alden Gates</td>\n",
       "      <td>male</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown, Mrs. James Joseph (Margaret Tobin)</td>\n",
       "      <td>female</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17610</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>B4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carrau, Mr. Francisco M</td>\n",
       "      <td>male</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113059</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Humblen, Mr. Adolf Mathias Nicolai Olsen</td>\n",
       "      <td>male</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>348121</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>F G63</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "851          852         0       3   \n",
       "42            43         0       3   \n",
       "288          289         1       2   \n",
       "473          474         1       2   \n",
       "766          767         0       1   \n",
       "528          529         0       3   \n",
       "78            79         1       2   \n",
       "194          195         1       1   \n",
       "83            84         0       1   \n",
       "699          700         0       3   \n",
       "\n",
       "                                             Name     Sex    Age  SibSp  \\\n",
       "851                           Svensson, Mr. Johan    male  74.00      0   \n",
       "42                            Kraeff, Mr. Theodor    male    NaN      0   \n",
       "288                          Hosono, Mr. Masabumi    male  42.00      0   \n",
       "473  Jerwan, Mrs. Amin S (Marie Marthe Thuillard)  female  23.00      0   \n",
       "766                     Brewe, Dr. Arthur Jackson    male    NaN      0   \n",
       "528                     Salonen, Mr. Johan Werner    male  39.00      0   \n",
       "78                  Caldwell, Master. Alden Gates    male   0.83      0   \n",
       "194     Brown, Mrs. James Joseph (Margaret Tobin)  female  44.00      0   \n",
       "83                        Carrau, Mr. Francisco M    male  28.00      0   \n",
       "699      Humblen, Mr. Adolf Mathias Nicolai Olsen    male  42.00      0   \n",
       "\n",
       "     Parch           Ticket     Fare  Cabin Embarked  \n",
       "851      0           347060   7.7750    NaN        S  \n",
       "42       0           349253   7.8958    NaN        C  \n",
       "288      0           237798  13.0000    NaN        S  \n",
       "473      0  SC/AH Basle 541  13.7917      D        C  \n",
       "766      0           112379  39.6000    NaN        C  \n",
       "528      0          3101296   7.9250    NaN        S  \n",
       "78       2           248738  29.0000    NaN        S  \n",
       "194      0         PC 17610  27.7208     B4        C  \n",
       "83       0           113059  47.1000    NaN        S  \n",
       "699      0           348121   7.6500  F G63        S  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.iloc[:, 1]\n",
    "X_train = train_df.iloc[:, 2:].drop(['Name', 'Cabin', 'Ticket'], axis=1)\n",
    "y_test = test_df.iloc[:, 1]\n",
    "X_test = test_df.iloc[:, 1:].drop(['Name', 'Cabin', 'Ticket'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('SImp', SimpleImputer(strategy='median')),\n",
    "    ('RandForestC', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'RandForestC__max_depth': [6, 7, 8, 9],\n",
    "    'RandForestC__n_estimators': [50,  60,  70,  80,  90, 100],\n",
    "    'RandForestC__min_samples_split': [2, 5, 10],\n",
    "    'RandForestC__bootstrap': [True, False]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = GridSearchCV(\n",
    "    cv=5,\n",
    "    estimator=pipe,\n",
    "    param_grid=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('SImp',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('RandForestC',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'RandForestC__bootstrap': [True, False],\n",
       "                         'RandForestC__max_depth': [6, 7, 8, 9],\n",
       "                         'RandForestC__min_samples_split': [2, 5, 10],\n",
       "                         'RandForestC__n_estimators': [50, 60, 70, 80, 90,\n",
       "                                                       100]})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandForestC__bootstrap': True,\n",
       " 'RandForestC__max_depth': 9,\n",
       " 'RandForestC__min_samples_split': 2,\n",
       " 'RandForestC__n_estimators': 80}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 1.9378 degrees.\n",
      "Accuracy = 21.73%.\n"
     ]
    }
   ],
   "source": [
    "predictions = cv_model.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "mape = 100 * np.mean(errors / y_test)\n",
    "accuracy = 100 - mape\n",
    "print('Model Performance')\n",
    "print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "print('Accuracy = {:0.2f}%.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### - Exercici 2\n",
    "Agafa un text en anglès que vulguis, i calcula'n la freqüència de les paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "text = response.read().decode('utf8')\n",
    "text = re.sub(\"[^-9A-Za-z ]\", \"\" , text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marcr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token=nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 6400, 'and': 5426, 'to': 4690, 'a': 3946, 'of': 3366, 'I': 3301, 'he': 3108, 'you': 2930, 'in': 2749, 'was': 2440, ...})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(text_token)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Nivell 2\n",
    "### - Exercici 1\n",
    "Treu les stopwords i realitza stemming al teu conjunt de dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marcr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " 'Crime',\n",
       " 'Punishment',\n",
       " 'Fyodor',\n",
       " 'DostoevskyThis',\n",
       " 'eBook',\n",
       " 'use',\n",
       " 'anyone']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "text_filtered = [w for w in text_token if not w.lower() in stop_words]\n",
    "text_filtered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'englishcharact',\n",
       " 'petersburg',\n",
       " 'the',\n",
       " 'you',\n",
       " 'case',\n",
       " '9',\n",
       " 'his',\n",
       " 'more',\n",
       " 'a',\n",
       " 'inhimself',\n",
       " 'he',\n",
       " 'or',\n",
       " 'pain',\n",
       " 'not',\n",
       " 'charact',\n",
       " 'somewher',\n",
       " 'this',\n",
       " 'mani',\n",
       " 'of',\n",
       " 'the',\n",
       " 'porterswho',\n",
       " 'bell',\n",
       " 'him',\n",
       " 'i',\n",
       " 'of',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'the',\n",
       " 'was',\n",
       " 'the',\n",
       " 'say',\n",
       " 'say',\n",
       " 'in',\n",
       " 'repuls',\n",
       " 'men',\n",
       " 'is',\n",
       " 'the',\n",
       " 'sleep',\n",
       " 'apart',\n",
       " 'might',\n",
       " 'thecount',\n",
       " 'because',\n",
       " 'there',\n",
       " 'brush',\n",
       " 'titularcounsellor',\n",
       " 'and',\n",
       " 'a',\n",
       " 'you',\n",
       " 'general',\n",
       " 'to',\n",
       " 'you',\n",
       " 'where',\n",
       " 'on',\n",
       " 'began',\n",
       " 'magnanim',\n",
       " 'the',\n",
       " 'children',\n",
       " 'that',\n",
       " 'of',\n",
       " 'be',\n",
       " 'paid',\n",
       " 'she',\n",
       " 'dont',\n",
       " 'do',\n",
       " 'is',\n",
       " 'read',\n",
       " 'has',\n",
       " 'thelittl',\n",
       " 'dont',\n",
       " 'not',\n",
       " 'both',\n",
       " 'our',\n",
       " 'give',\n",
       " 'man',\n",
       " 'servic',\n",
       " 'of',\n",
       " 'to',\n",
       " 'visit',\n",
       " 'degre',\n",
       " 'weve',\n",
       " 'littl',\n",
       " 'marmeladov',\n",
       " 'restor',\n",
       " 'and',\n",
       " 'to',\n",
       " 'for',\n",
       " 'me',\n",
       " 'to',\n",
       " 'and',\n",
       " 'i',\n",
       " 'oh',\n",
       " 'in',\n",
       " 'two',\n",
       " 'they',\n",
       " 'it',\n",
       " 'full',\n",
       " 'tallslim',\n",
       " 'come',\n",
       " 'tall',\n",
       " 'stranger',\n",
       " 'themoney',\n",
       " 'strike',\n",
       " 'with',\n",
       " 'was',\n",
       " 'have',\n",
       " 'and',\n",
       " 'bilious',\n",
       " 'had',\n",
       " 'toraskolnikov',\n",
       " 'entir',\n",
       " 'side',\n",
       " 'countrypeasant-woman',\n",
       " 'onetim',\n",
       " 'littl',\n",
       " 'for',\n",
       " 'he',\n",
       " 'you',\n",
       " 'pensionfrom',\n",
       " 'been',\n",
       " 'you',\n",
       " 'without',\n",
       " 'attabl',\n",
       " 'contempt',\n",
       " 'onaccount',\n",
       " 'maintain',\n",
       " 'to',\n",
       " 'yet',\n",
       " 'shame',\n",
       " 'the',\n",
       " 'hand',\n",
       " 'tooclear',\n",
       " 'besought',\n",
       " 'they',\n",
       " 'the',\n",
       " 'consent',\n",
       " 'next',\n",
       " 'a',\n",
       " 'one',\n",
       " 'to',\n",
       " 'the',\n",
       " 'and',\n",
       " 'i',\n",
       " 'was',\n",
       " 'rodya',\n",
       " 'on',\n",
       " 'busi',\n",
       " 'very',\n",
       " 'salari',\n",
       " 'simpli',\n",
       " 'sake',\n",
       " 'a',\n",
       " 'she',\n",
       " 'will',\n",
       " 'the',\n",
       " 'have',\n",
       " 'to-day',\n",
       " 'his',\n",
       " 'to',\n",
       " 'arrang',\n",
       " 'man',\n",
       " 'like',\n",
       " 'whowould',\n",
       " 'true',\n",
       " 'to',\n",
       " 'to',\n",
       " 'themarriag',\n",
       " 'he',\n",
       " 'i',\n",
       " 'that',\n",
       " 'he',\n",
       " 'are',\n",
       " 'the',\n",
       " 'we',\n",
       " 'a',\n",
       " 'up',\n",
       " 'mother',\n",
       " 'your',\n",
       " 'be',\n",
       " 'form',\n",
       " 'understand',\n",
       " 'quit',\n",
       " 'but',\n",
       " 'be',\n",
       " 'theseat',\n",
       " 'leg',\n",
       " 'but',\n",
       " 'stern',\n",
       " 'a',\n",
       " 'been',\n",
       " 'wait',\n",
       " 'address',\n",
       " 'he',\n",
       " 'alreadi',\n",
       " 'is',\n",
       " 'which',\n",
       " 'him',\n",
       " 'letthem',\n",
       " 'a',\n",
       " 'to',\n",
       " 'came',\n",
       " 'gather',\n",
       " 'he',\n",
       " 'drink',\n",
       " 'present',\n",
       " 'go',\n",
       " 'kept',\n",
       " 'everyth',\n",
       " 'heat',\n",
       " 'his',\n",
       " 'themwith',\n",
       " 'finish',\n",
       " 'detail',\n",
       " 'recal',\n",
       " 'hang',\n",
       " 'on',\n",
       " 'down',\n",
       " 'of',\n",
       " 'evenabout',\n",
       " 'thecrowdtak',\n",
       " 'whip',\n",
       " 'was',\n",
       " 'could',\n",
       " 'was',\n",
       " 'by',\n",
       " 'her',\n",
       " 'he',\n",
       " 'butlurch',\n",
       " 'thirdil',\n",
       " 'the',\n",
       " 'eye',\n",
       " 'cri',\n",
       " 'ishal',\n",
       " 'as',\n",
       " 'went',\n",
       " 'abscess',\n",
       " 'had',\n",
       " 'very',\n",
       " 'he',\n",
       " 'about',\n",
       " 'ivanovna',\n",
       " 'on',\n",
       " 'wouldb',\n",
       " 'would',\n",
       " 'marketthey',\n",
       " 'left',\n",
       " 'he',\n",
       " 'him',\n",
       " 'her',\n",
       " 'lizaveta',\n",
       " 'kindwithout',\n",
       " 'the',\n",
       " 'damnedold',\n",
       " 'excitedcompanion',\n",
       " 'wipe',\n",
       " 'natureoh',\n",
       " 'todo',\n",
       " 'thiscoincid',\n",
       " 'down',\n",
       " 'no',\n",
       " 'of',\n",
       " 'in',\n",
       " 'his',\n",
       " 'but',\n",
       " 'materi',\n",
       " 'would',\n",
       " 'with',\n",
       " 'which',\n",
       " 'byhim',\n",
       " 'on',\n",
       " 'someth',\n",
       " 'but',\n",
       " 'seemedutt',\n",
       " 'casuistri',\n",
       " 'impossibilityof',\n",
       " 'rise',\n",
       " 'purelymateri',\n",
       " 'usual',\n",
       " 'he',\n",
       " 'a',\n",
       " 'it',\n",
       " 'get',\n",
       " 'noth',\n",
       " 'therear',\n",
       " 'seven',\n",
       " 'not',\n",
       " 'still',\n",
       " 'staircas',\n",
       " 'was',\n",
       " 'to',\n",
       " 'raskolnikov',\n",
       " 'to',\n",
       " 'glanc',\n",
       " 'like',\n",
       " 'difficulti',\n",
       " 'but',\n",
       " 'not',\n",
       " 'thepledg',\n",
       " 'he',\n",
       " 'to',\n",
       " 'woman',\n",
       " 'the',\n",
       " 'purs',\n",
       " 'key',\n",
       " 'the',\n",
       " 'turn',\n",
       " 'must',\n",
       " 'over',\n",
       " 'to',\n",
       " 'long',\n",
       " 'of',\n",
       " 'in',\n",
       " 'axe',\n",
       " 'himself',\n",
       " 'god',\n",
       " 'separ',\n",
       " 'the',\n",
       " 'to',\n",
       " 'hand',\n",
       " 'it',\n",
       " 'not',\n",
       " 'can',\n",
       " 'backhm',\n",
       " 'the',\n",
       " 'i',\n",
       " 'tight',\n",
       " 'he',\n",
       " 'shout',\n",
       " 'approach',\n",
       " 'the',\n",
       " 'realis',\n",
       " 'it',\n",
       " 'moreconspicu',\n",
       " 'in',\n",
       " 'on',\n",
       " 'it',\n",
       " 'everyth',\n",
       " 'undress',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hide',\n",
       " 'frenzi',\n",
       " 'the',\n",
       " 'not',\n",
       " 'and',\n",
       " 'of',\n",
       " 'at',\n",
       " 'door',\n",
       " 'paperfrom',\n",
       " 'go',\n",
       " 'hisey',\n",
       " 'one',\n",
       " 'not',\n",
       " 'top',\n",
       " 'the',\n",
       " 'out',\n",
       " 'old',\n",
       " 'smell',\n",
       " 'than',\n",
       " 'small',\n",
       " 'to',\n",
       " 'man',\n",
       " 'soft',\n",
       " 'down',\n",
       " 'hiscloth',\n",
       " 'pray',\n",
       " 'was',\n",
       " 'dont',\n",
       " 'liberti',\n",
       " 'at',\n",
       " 'joy',\n",
       " 'warn',\n",
       " 'at',\n",
       " 'mr',\n",
       " 'hit',\n",
       " 'i',\n",
       " 'your',\n",
       " 'and',\n",
       " 'step',\n",
       " 'here',\n",
       " 'bottom',\n",
       " 'and',\n",
       " 'explain',\n",
       " 'my',\n",
       " 'and',\n",
       " 'detail',\n",
       " 'instant',\n",
       " 'him',\n",
       " 'had',\n",
       " 'and',\n",
       " 'happen',\n",
       " 'inform',\n",
       " 'considerbut',\n",
       " 'axe',\n",
       " 'intent',\n",
       " 'and',\n",
       " 'pass',\n",
       " 'littl',\n",
       " 'anoth',\n",
       " 'turn',\n",
       " 'float',\n",
       " 'of',\n",
       " 'him',\n",
       " 'some',\n",
       " 'a',\n",
       " 'smallhollow',\n",
       " 'who',\n",
       " 'be',\n",
       " 'it',\n",
       " 'had',\n",
       " 'settl',\n",
       " 'not',\n",
       " 'of',\n",
       " 'bare',\n",
       " 'come',\n",
       " 'said',\n",
       " 'alonestay',\n",
       " 'has',\n",
       " 'roublesfor',\n",
       " 'on',\n",
       " 'wors',\n",
       " 'want',\n",
       " 'his',\n",
       " 'on',\n",
       " 'chapel',\n",
       " 'pictur',\n",
       " 'down',\n",
       " 'and',\n",
       " 'agoni',\n",
       " 'voic',\n",
       " 'would',\n",
       " 'their',\n",
       " 'he',\n",
       " 'you',\n",
       " 'ear',\n",
       " 'want',\n",
       " 'part',\n",
       " 'rightwal',\n",
       " 'at',\n",
       " 'not',\n",
       " 'have',\n",
       " 'pleasesir',\n",
       " 'raskolnikov',\n",
       " 'what',\n",
       " 'on',\n",
       " 'answer',\n",
       " 'was',\n",
       " 'him',\n",
       " 'you',\n",
       " 'his',\n",
       " 'possessionof',\n",
       " 'on',\n",
       " 'at',\n",
       " 'brother',\n",
       " 'to',\n",
       " 'will',\n",
       " 'is',\n",
       " 'lesson',\n",
       " 'you',\n",
       " 'do',\n",
       " 'clear',\n",
       " 'i',\n",
       " 'except',\n",
       " 'rave',\n",
       " 'wretchedth',\n",
       " 'away',\n",
       " 'he',\n",
       " 'walk',\n",
       " 'under',\n",
       " 'escap',\n",
       " 'they',\n",
       " 'thequilt',\n",
       " 'nastasya',\n",
       " 'out',\n",
       " 'alon',\n",
       " 'boy',\n",
       " 'two',\n",
       " 'let',\n",
       " 'its',\n",
       " 'there',\n",
       " 'this',\n",
       " 'set',\n",
       " 'purchasescom',\n",
       " 'frown',\n",
       " 'appar',\n",
       " 'well',\n",
       " 'to-morrowperhap',\n",
       " 'whoall',\n",
       " 'much',\n",
       " 'irrit',\n",
       " 'be',\n",
       " 'interest',\n",
       " 'his',\n",
       " 'youv',\n",
       " 'respect',\n",
       " 'might',\n",
       " 'dandl',\n",
       " 'where',\n",
       " 'lie',\n",
       " 'got',\n",
       " 'at',\n",
       " 'what',\n",
       " 'you',\n",
       " 'at',\n",
       " 'woman',\n",
       " 'you',\n",
       " 'the',\n",
       " 'so',\n",
       " 'swore',\n",
       " 'had',\n",
       " 'turn',\n",
       " 'you',\n",
       " 'hand',\n",
       " 'but',\n",
       " 'block',\n",
       " 'theyd',\n",
       " 'not',\n",
       " 'excit',\n",
       " 'inde',\n",
       " 'real',\n",
       " 'in',\n",
       " 'all',\n",
       " 'and',\n",
       " 'ground',\n",
       " 'extrem',\n",
       " 'and',\n",
       " 'you',\n",
       " 'last',\n",
       " 'good-naturethat',\n",
       " 'fianc',\n",
       " 'appli',\n",
       " 'had',\n",
       " 'younger',\n",
       " 'his',\n",
       " 'have',\n",
       " 'is',\n",
       " 'peopl',\n",
       " 'say',\n",
       " 'have',\n",
       " 'to',\n",
       " 'coat',\n",
       " 'speak',\n",
       " 'incess',\n",
       " 'dear',\n",
       " 'doesnt',\n",
       " 'and',\n",
       " 'head',\n",
       " 'on',\n",
       " 'this',\n",
       " 'upshot',\n",
       " 'put',\n",
       " 'benefactorupon',\n",
       " 'cri',\n",
       " 'find',\n",
       " 'even',\n",
       " 'not',\n",
       " 'in',\n",
       " 'you',\n",
       " 'mutter',\n",
       " 'landladi',\n",
       " 'not',\n",
       " 'of',\n",
       " 'said',\n",
       " 'and',\n",
       " 'at',\n",
       " 'vhe',\n",
       " 'of',\n",
       " 'forti',\n",
       " 'i',\n",
       " 'sli',\n",
       " 'that',\n",
       " 'it',\n",
       " 'which',\n",
       " 'spontan',\n",
       " 'thewatch-chain',\n",
       " 'new',\n",
       " 'champagn',\n",
       " 'strang',\n",
       " 'cock-sparrow',\n",
       " 'you',\n",
       " 'what',\n",
       " 'nervous',\n",
       " 'come',\n",
       " 'been',\n",
       " 'anoth',\n",
       " 'the',\n",
       " 'face',\n",
       " 'the',\n",
       " 'would',\n",
       " 'save',\n",
       " 'murder',\n",
       " 'zametov',\n",
       " 'would',\n",
       " 'a',\n",
       " 'yes',\n",
       " 'for',\n",
       " 'reviv',\n",
       " 'fierc',\n",
       " 'for',\n",
       " 'curs',\n",
       " 'my',\n",
       " 'of',\n",
       " 'i',\n",
       " 'you',\n",
       " 'razumihin',\n",
       " 'how',\n",
       " 'pink',\n",
       " 'woman',\n",
       " 'dozen',\n",
       " 'with',\n",
       " 'troubl',\n",
       " 'move',\n",
       " 'it',\n",
       " 'possibl',\n",
       " 'land',\n",
       " 'that',\n",
       " 'their',\n",
       " 'of',\n",
       " 'in',\n",
       " 'want',\n",
       " 'to',\n",
       " 'made',\n",
       " 'not',\n",
       " 'mutter',\n",
       " 'observ',\n",
       " 'stone',\n",
       " 'carriag',\n",
       " 'object',\n",
       " 'stagger',\n",
       " 'a',\n",
       " 'his',\n",
       " 'and',\n",
       " 'your',\n",
       " 'unwel',\n",
       " 'turn',\n",
       " 'from',\n",
       " 'cough',\n",
       " 'come',\n",
       " 'way',\n",
       " 'to',\n",
       " 'you',\n",
       " 'work',\n",
       " 'run',\n",
       " 'from',\n",
       " 'of',\n",
       " 'just',\n",
       " 'ludwigovna',\n",
       " 'princ',\n",
       " 'him',\n",
       " 'walk',\n",
       " 'somethingwhat',\n",
       " 'a',\n",
       " 'you',\n",
       " 'stove',\n",
       " 'passag',\n",
       " 'despair',\n",
       " 'and',\n",
       " 'and',\n",
       " 'away',\n",
       " 'to-day',\n",
       " 'priest',\n",
       " 'in',\n",
       " 'cri',\n",
       " 'all',\n",
       " 'squeez',\n",
       " 'inhi',\n",
       " 'was',\n",
       " 'shoulder',\n",
       " 'to',\n",
       " 'ill',\n",
       " 'sister',\n",
       " 'the',\n",
       " 'livein',\n",
       " 'pride',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'mustand',\n",
       " 'talk',\n",
       " 'allamiss',\n",
       " 'if',\n",
       " 'ventur',\n",
       " 'listen',\n",
       " 'you',\n",
       " 'did',\n",
       " 'but',\n",
       " 'never',\n",
       " 'the',\n",
       " 'they',\n",
       " 'who',\n",
       " 'their',\n",
       " 'time',\n",
       " 'therehow',\n",
       " 'kind',\n",
       " 'opportun',\n",
       " 'to-morrow',\n",
       " 'one',\n",
       " 'anyway',\n",
       " 'find',\n",
       " 'the',\n",
       " 'closer',\n",
       " 'prevent',\n",
       " 'nastasya',\n",
       " 'is',\n",
       " 'its',\n",
       " 'betteryou',\n",
       " 'along',\n",
       " 'love',\n",
       " 'of',\n",
       " 'not',\n",
       " 'and',\n",
       " 'to',\n",
       " 'he',\n",
       " 'for',\n",
       " 'in',\n",
       " 'thoughal',\n",
       " 'go',\n",
       " 'i',\n",
       " 'consol',\n",
       " 'in',\n",
       " 'detract',\n",
       " 'was',\n",
       " 'he',\n",
       " 'littl',\n",
       " 'backi',\n",
       " 'near',\n",
       " 'reserv',\n",
       " 'it',\n",
       " 'had',\n",
       " 'a',\n",
       " 'a',\n",
       " 'know',\n",
       " 'have',\n",
       " 'genuin',\n",
       " 'follybut',\n",
       " 'shes',\n",
       " 'world',\n",
       " 'once',\n",
       " 'felt',\n",
       " 'such',\n",
       " 'of',\n",
       " 'and',\n",
       " 'his',\n",
       " 'dirti',\n",
       " 'who',\n",
       " 'no',\n",
       " 'him',\n",
       " 'iknow',\n",
       " 'you',\n",
       " 'praskovya',\n",
       " 'kiss',\n",
       " 'inquiri',\n",
       " 'knew',\n",
       " 'arehi',\n",
       " 'you',\n",
       " 'bed',\n",
       " 'for',\n",
       " 'poor',\n",
       " 'and',\n",
       " 'but',\n",
       " 'yousuppos',\n",
       " 'at',\n",
       " 'heror',\n",
       " 'himselfso',\n",
       " 'ith',\n",
       " 'a',\n",
       " 'us',\n",
       " 'ofdelay',\n",
       " 'certain',\n",
       " 'to',\n",
       " 'avdotya',\n",
       " 'cost',\n",
       " 'splendid',\n",
       " 'digniti',\n",
       " 'all',\n",
       " 'about',\n",
       " 'his',\n",
       " 'behappi',\n",
       " 'before',\n",
       " 'want',\n",
       " 'to',\n",
       " 'friend',\n",
       " 'should',\n",
       " 'withoutoccup',\n",
       " 'journeyach',\n",
       " 'fellow',\n",
       " 'you',\n",
       " 'ecstat',\n",
       " 'heaven',\n",
       " 'woman',\n",
       " 'point',\n",
       " 'are',\n",
       " 'everyth',\n",
       " 'latter',\n",
       " 'raskolnikov',\n",
       " 'right',\n",
       " 'i',\n",
       " 'dead',\n",
       " 'was',\n",
       " 'immedi',\n",
       " 'why',\n",
       " 'thetrain',\n",
       " 'had',\n",
       " 'someth',\n",
       " 'splendid',\n",
       " 'gone',\n",
       " 'he',\n",
       " 'i',\n",
       " 'alexandrovna',\n",
       " 'you',\n",
       " 'was',\n",
       " 'and',\n",
       " 'to',\n",
       " 'himself',\n",
       " 'of',\n",
       " 'me',\n",
       " 'at',\n",
       " 'not',\n",
       " 'that',\n",
       " 'a',\n",
       " 'express',\n",
       " 'slanderm',\n",
       " 'sudden',\n",
       " 'atthi',\n",
       " 'semyonovna',\n",
       " 'about',\n",
       " 'when',\n",
       " 'torazumihin',\n",
       " 'us',\n",
       " 'said',\n",
       " 'the',\n",
       " 'you',\n",
       " 'characterist',\n",
       " 'islik',\n",
       " 'rodya',\n",
       " 'douniarazumihin',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'and',\n",
       " 'the',\n",
       " 'will',\n",
       " 'turnedsudden',\n",
       " 'to',\n",
       " 'razumihinshout',\n",
       " 'look',\n",
       " 'semyonovna',\n",
       " 'not',\n",
       " 'onceon',\n",
       " 'was',\n",
       " 'behind',\n",
       " 'cold',\n",
       " 'tailor',\n",
       " 'he',\n",
       " 'emphasi',\n",
       " 'you',\n",
       " 'see',\n",
       " 'els',\n",
       " 'thing',\n",
       " 'he',\n",
       " 'you',\n",
       " 'i',\n",
       " 'an',\n",
       " 'he',\n",
       " 'confus',\n",
       " 'that',\n",
       " 'laugh',\n",
       " 'troubl',\n",
       " 'waterymawkish',\n",
       " 'import',\n",
       " 'that',\n",
       " 'as',\n",
       " 'themparticular',\n",
       " 'or',\n",
       " 'did',\n",
       " 'know',\n",
       " 'know',\n",
       " 'you',\n",
       " 'it',\n",
       " 'you',\n",
       " 'pleas',\n",
       " 'worst',\n",
       " 'could',\n",
       " 'could',\n",
       " 'helet',\n",
       " 'to',\n",
       " 'told',\n",
       " 'porfiri',\n",
       " 'becom',\n",
       " 'smell',\n",
       " 'easiest',\n",
       " 'to',\n",
       " 'use',\n",
       " 'fantasyah',\n",
       " 'certain',\n",
       " 'that',\n",
       " 'is',\n",
       " 'of',\n",
       " 'decid',\n",
       " 'is',\n",
       " 'whole',\n",
       " 'were',\n",
       " 'you',\n",
       " 'are',\n",
       " 'his',\n",
       " 'generat',\n",
       " 'do',\n",
       " 'extraordinarypeopl',\n",
       " 'is',\n",
       " 'and',\n",
       " 'to',\n",
       " 'and',\n",
       " 'therecertain',\n",
       " 'your',\n",
       " 'clear',\n",
       " 'must',\n",
       " 'you',\n",
       " 'the',\n",
       " 'a',\n",
       " 'articl',\n",
       " 'firm',\n",
       " 'abl',\n",
       " 'one',\n",
       " 'while',\n",
       " 'there',\n",
       " 'itthen',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'their',\n",
       " 'vain',\n",
       " 'in',\n",
       " 'of',\n",
       " 'thing',\n",
       " 'of',\n",
       " 'thing',\n",
       " 'relish',\n",
       " 'on',\n",
       " 'his',\n",
       " 'took',\n",
       " 'discontentedlywhat',\n",
       " 'stranger',\n",
       " 'answer',\n",
       " 'pace',\n",
       " 'of',\n",
       " 'recal',\n",
       " 'the',\n",
       " 'it',\n",
       " 'know',\n",
       " 'bronzeon',\n",
       " 'tooverstep',\n",
       " 'my',\n",
       " 'to',\n",
       " 'lous',\n",
       " 'hisey',\n",
       " 'lizaveta',\n",
       " 'workmen',\n",
       " 'realli',\n",
       " 'raskolnikov',\n",
       " 'he',\n",
       " 'it',\n",
       " 'quietlyand',\n",
       " 'and',\n",
       " 'of',\n",
       " 'still',\n",
       " 'stout',\n",
       " 'it',\n",
       " 'only',\n",
       " 'that',\n",
       " 'raskolnikov',\n",
       " 'one',\n",
       " 'prove',\n",
       " 'for',\n",
       " 'glad',\n",
       " 'i',\n",
       " 'you',\n",
       " 'truli',\n",
       " 'you',\n",
       " 'well',\n",
       " 'have',\n",
       " 'of',\n",
       " 'a',\n",
       " 'law',\n",
       " 'restrain',\n",
       " 'i',\n",
       " 'see',\n",
       " 'me',\n",
       " 'out',\n",
       " 'by',\n",
       " 'cigar',\n",
       " 'journey',\n",
       " 'she',\n",
       " 'all',\n",
       " 'just',\n",
       " 'with',\n",
       " 'thebegin',\n",
       " 'believ',\n",
       " 'comfort',\n",
       " 'raskolnikov',\n",
       " 'you',\n",
       " 'i',\n",
       " 'deprav',\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "text_stem = [stemmer.stem(word) for word in text_token]\n",
    "text_stem[1::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nivell 3\n",
    "### - Exercici 1\n",
    "Realitza sentiment analysis al teu conjunt de dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/marcr/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.11, 'neu': 0.789, 'pos': 0.101, 'compound': -1.0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos\n",
    "Recursos de l'aula i https://www.nltk.org\n",
    "\n",
    "## Objectius\n",
    "Utilitzar pipelines i grid search\n",
    "Realitzar mineria de texts"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5914541f2d90b2e855d49965b24e76b320c7eb9f698d7470eec85d33c9427069"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
